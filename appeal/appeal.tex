\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{xcolor}
\usepackage{amsmath}
\usepackage{hyperref}
\title{IDL - Appeal, Exam B. }
\author{David Ponarovsky}
\date{August 2025}

    \newcommand{\DXX}[1]{ \frac{d}{ d #1 } }
    \newcommand{\inb}[1]{ \color{blue}#1 \color{black} }
\begin{document}

\maketitle

\paragraph{ Question 7 - RNN nets.} 
Does a recursive net of type Elman, that gets the zero vector as input at each step, can count? Namely, outputs the value $t$ at its $t$-th step?
\begin{enumerate}
  \item Yes
  \item No
  \item In general No, Yet when $t$ is given as initial input, yes. 
\end{enumerate}
\inb{ My answer: (3), Correct answer: (1)}. 
%I believe that the confusion emits form the order of entetis, The question: 'Is there an Elman cell that can count until $t$ for an arbitrary $t$?' is a different question than: 'Fix $t$, is there exist an Elman cell that can count until $t$'? 

%For, the second question: There is family of unbound fan-in/out circuits, at width $poly(|t|)$ (the length of the encoding of $t$), that implement addition: \href{https://people.clarkson.edu/~alexis/PCMI/Notes/lectureB02.pdf}{[addition in $AC_{0}$]}. 
%It's not hard to see that the implementation in the notes can realized using Elman cell, and there fore one can find such realization that adds $1$ to the input which is entered via the hidden channel.  

%For the first question, in which we first fix the Elman cell architecture, and therefore also fix the width of the output. Thus the number can be outputted using the cell has to has a suitable length and can not be arbitrary.

%I marked the third option since, saying 'on given $t$ as initial input' implies that $t$ is validate input/token to the cell, namely has length which matches the cells weights.  

I believe that the confusion arises from the order of entities. The question: 'Is there an Elman cell that can count until $t$ for an arbitrary $t$?' is a different question than: 'Fix $t$, does there exist an Elman cell that can count until $t$?'

For the \textbf{second} question: There is a family of unbounded fan-in/out circuits, at width $poly(|t|)$ (the length of the encoding of $t$), that implement addition: \href{https://people.clarkson.edu/~alexis/PCMI/Notes/lectureB02.pdf}{[addition in $AC_{0}$]}. It's not hard to see that the implementation in the notes can be realized using an Elman cell, and therefore one can find such a realization that adds $1$ to the input which is entered via the hidden channel.

For the \textbf{first} question, in which we first fix the Elman cell architecture, and therefore also fix the width of the output. Thus, the number that can be outputted using the cell has to have a suitable length and cannot be arbitrary.

%I marked the third option since saying 'on given $t$ as initial input' implies that $t$ is a valid input/token to the cell, namely has a length that matches the cell's weights. For such $t$'s, the RNN counts correctly, when for others, the behavior of giving the input is not well defined, and excepted to be a failure.  
I marked the third option since saying 'on given $t$ as initial input' implies that $t$ is a valid input/token to the cell, namely, it has a length that matches the cell's weights. For such $t$'s, the RNN counts correctly, whereas for others, the behavior of giving the input is not well defined and is expected to be a failure.


%\paragraph{ Question 8 - Inception Score. } Which of the following scenarios is expected to yield high IS score, although the generated images are at low quality?
%\begin{enumerate}
  %\item The model generates a blurred images, yet with high number of categorical.  
  %\item The model generates clear elements that are easy to classify, Yet the elements (inside them) are unrealistic. 
  %\item The model generates good images and then add them a random noise. 
  %\item The model generates images with high variance between the outputs at the pixels level, but their sementic content repeats on itself.    
%\end{enumerate}
\paragraph{Question 14 - VAEs.} What is the reason for the generated images by VAEs being blurred compared to the images generated by GANs?   
\begin{enumerate}
  \item Usage of reconstruction loss that smooths sharp items.   
  \item KL-divergence element that impairs the disentanglement (or separation) of different samples in the latent space. 
  \item Low representation ability of the VAE architecture. 
  \item Entering too much noise into the latent space, which after decoding results in a blurred image. 
\end{enumerate}

\inb{ My answer: (1), Correct answer: (2)}. 
%I agree that, in general, the main reason for the results of the VEAs being blurred is the KL-divergence term, In particular it enforces the decoder to decode a sampled super-position over the latent space. Yet the question asks what is the main reason for blurriness compared to GANs.  
%
%When comparing to GANs, which, in our course, have an amorphic architecture and can be arbitrarily complex, one should also consider the case when the architecture of the VEAs is as exactly complicated as in GANs, surly if in that regime the VEAs products are still inferior. 
%
%
%In that regime, one could think on a \textbf{decoder} which expands the latent dimension so mach, such that for human eye (Or more correctly to latent-space eye) the interpolation $D(tz_{1} + (1-t)z_{2})$ is not a continues function. In that case, even though that the KL-element enforce the latent vector $z$ be distributed according gaussian, any value of $z$ that can be seen in experiment leads to other value $x$ in the data space.  
%
%For example, consider that the latent space has a width of $k$ bits (For the sake of the exercise, you can imagine that the numbers at the latent space are in $(0,1)$), and the decoder decode each $z$ to a space represented by $n = 2^{k}$ bits, such that $D(z) = 2^{ z * 2^{k} }$ (shifting by the integer suitable to $z$). Clearly, close samples at the latent space gets far in the domain space. That argument cancel any justification due to behavior or panellization in the latent space. 
%
%That bring us to ask if there is difference in the case which is the latent space is trivial. Namely, when it's dimension is $0$ (it's size is $1$), namely a constant machine ('generates only cat, and always the same cat'). In that case optimal generator and discriminator in GANs would be the generator which output the same cat, and discriminator which guess at probability $\frac{1}{2}$, while in the VEA scheme any generator which outputs a noise version of the same cat, would penalize by only $\frac{\varepsilon}{\sqrt{n}}$ if the reconstraction error is $l_2$, that loss is going to zero when the domain dimension is increasing. 
%To complete that argument we have to show in the GANs setting that  generationn noisy version of cats would have a non trivial loss cost. We show that by defing the following simple descriminator. On given $\tilde{x}$ take the subtraction of $\Delta \leftarrow \tilde{x} - \text{The-Cat}$. If $\Delta$ is non-zero then mark $\tilde{x}$ as  generated image.
%
%Hence, we showed that the source for GANs to output a sharper images than their complex- equiviliance VAEs enemates from the choice of the reconstraction loss.
%
I agree that, in general, the main reason for the results of the VEAs being blurred is the KL-divergence term. In particular, it enforces the decoder to decode a sampled superposition over the latent space. Yet the question asks what is the main reason for blurriness compared to GANs.

When comparing to GANs, which, in our course, have an amorphic architecture and can be arbitrarily complex, one should also consider the case when the architecture of the VEAs is exactly as complicated as in GANs, surely if in that regime the VEAs products are still inferior.

In that regime, one could think of a \textbf{decoder} which expands the latent dimension so much, such that for the human eye (or more correctly to the latent-space eye) the interpolation $D(tz_{1} + (1-t)z_{2})$ is not a continuous function. In that case, even though the KL-element enforces the latent vector $z$ to be distributed according to a Gaussian, any value of $z$ that can be seen in the experiment leads to another (isolated) value $x$ in the data space.

For example, consider that the latent space has a width of $k$ bits (for the sake of the exercise, you can imagine that the entities in the latent space are numbers in $(0,1)$), and the decoder decodes each $z$ to a space represented by $n = 2^{k}$ bits, such that $D(z) = 2^{ z * 2^{k} }$ (shifting by the integer suitable to $z$). Clearly, close samples in the latent space get far in the domain space. That argument cancels any justification due to behavior or penalization in the latent space.

%That brings us to ask if there is a difference in the case where the latent space is trivial. Namely, when its dimension is $0$ (its size is $1$), namely a constant machine ('generates only cat, and always the same cat'). In that case, the optimal generator and discriminator in GANs would be the generator which outputs the same cat, and the discriminator which guesses at probability $\frac{1}{2}$, while in the VEA scheme any generator which outputs a noisy version of the same cat would be penalized by only $\frac{\varepsilon}{\sqrt{n}}$ if the reconstruction error is $l_2$ and noise is distributed independently over the pixels with mean $\varepsilon$, that loss is going to zero when the domain dimension is increasing. (If that reconstruction loss is a $l_{1}$ loss, then one should a correlative noise mode, for example, one that hits $\sqrt{n}$ of the bits on average, which match the bulring of the perimeter of the cat. ). 


That brings us to ask if there is a difference in the case where the latent space is trivial. Namely, when its dimension is $0$ (its size is $1$), namely a constant machine ('generates only a cat, and always the same cat'). In that case, the optimal generator and discriminator in GANs would be the generator which outputs the same cat, and the discriminator which guesses at probability $\frac{1}{2}$, while in the VEA scheme any generator which outputs a noisy version of the same cat would be penalized by only $\frac{\varepsilon}{\sqrt{n}}$ if the reconstruction error is $l_2$ and noise is distributed independently over the pixels with mean $\varepsilon$. That loss is going to zero when the domain dimension is increasing. (If that reconstruction loss is an $l_{1}$ loss, then one should use a correlative noise mode, for example, one that hits $\sqrt{n}$ of the bits on average, which matches the blurring of the perimeter of the cat.)

To complete that argument, we have to show in the GANs setting that generating noisy versions of cats would have a non-trivial loss cost. We show that by defining the following simple discriminator. On a given $\tilde{x}$, take the subtraction: $\Delta \leftarrow \tilde{x} - \text{The-Cat}$. If $\Delta$ is non-zero, then mark $\tilde{x}$ as a generated image.

Hence, we showed that the source for GANs to output sharper images than their complex-equivalence VAEs emanates from the choice of the reconstruction loss.

%for each different point  maps to gaussian at the 
%is indeed the main reason, for the we would expe

%Second, if the KL-divergence element is indeded the main source for the blurration, we would expect that WAEs for which the loss over the latent-space heads to advance $\mathbf{E}_{\sim x} \left[ \mathbf{Pr} \left[  Z | X \right]    \right] \rightarrow \sim e^{-z^{2}} $ instead of $ \mathbf{Pr} \left[  Z | X \right] \rightarrow \sim e^{-z^{2}} $ (for any $x$) would generates a significantly less blurred images. Indeed they exhibit improvements when compared to VEAs, yet they are still blurred compared to Gans.   




\end{document}

